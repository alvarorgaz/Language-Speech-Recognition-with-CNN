{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, GlobalAveragePooling1D, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model input features and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MELS = 80\n",
    "N_MFCC = 40\n",
    "FEATURES_TYPE = 'log-mel-spectrogram'\n",
    "FEATURES_SPEED = 1\n",
    "INPUT_FRAMES = 297 # number of features rows (or frames) for test audios of 3s or 48000 samples\n",
    "HOP_FRAMES_TRAIN_SPLIT = 100 # or INPUT_FRAMES\n",
    "FEATURES_NORMALIZED = False\n",
    "DROPOUT = 0\n",
    "REGULARIZATION = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the directories to load extracted features of train and test audio files as well the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'CNN_'+FEATURES_TYPE\n",
    "dir_train = '../data/features_extraction/train/'+FEATURES_TYPE\n",
    "dir_test = '../data/features_extraction/test/'+FEATURES_TYPE\n",
    "if 'mfcc' in FEATURES_TYPE:\n",
    "    dir_train += '_'+str(N_MFCC)\n",
    "    dir_test += '_'+str(N_MFCC)\n",
    "    model_id += '_'+str(N_MFCC)\n",
    "elif 'mel' in FEATURES_TYPE:\n",
    "    dir_train += '_'+str(N_MELS)\n",
    "    dir_test += '_'+str(N_MELS)\n",
    "    model_id += '_'+str(N_MELS)\n",
    "dir_train += ('' if FEATURES_SPEED==1 else '_speed'+str(FEATURES_SPEED))+'/'\n",
    "dir_test += ('' if FEATURES_SPEED==1 else '_speed'+str(FEATURES_SPEED))+'/'\n",
    "model_id += ('' if FEATURES_SPEED==1 else '_speed'+str(FEATURES_SPEED))\n",
    "model_id += ('' if HOP_FRAMES_TRAIN_SPLIT!=INPUT_FRAMES else '_NoHopTrainSplit3s')\n",
    "model_id += ('' if not FEATURES_NORMALIZED else '_features_normalized')\n",
    "model_id += ('' if DROPOUT==0 else '_dropout'+str(DROPOUT))\n",
    "model_id += ('' if REGULARIZATION==0 else '_regularization'+str(REGULARIZATION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train features and targets (into list of arrays for Keras fit generator).\n",
    "\n",
    "*Note:* I have to split the features of training audio files with different durations into splits of the same shape than the features of test audio files of exactly 3 seconds or 48000 samples at 16kHz of frequency. Since the features extraction configuration was *center=False*, *hop_length=160* and *n_fft=512*, for test audio files the features has INPUT_FRAMES=297 rows equivalent to 1+(48000-512)//160=297. Now I will use moving windows (number of frames between consecutive splits) of HOP_FRAMES_TRAIN_SPLIT=100 frames equivalent to 100*160=16000 samples or 1 second in order to: consider the time context of each audio, data augmentation and not discard many remaining frames after the last possible complete split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.loadtxt('../data/train_labels.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list, y_train_list = [], []\n",
    "for filename in os.listdir(dir_train):\n",
    "    features = np.load(dir_train+filename)\n",
    "    for i in range(0, features.shape[0]-INPUT_FRAMES, HOP_FRAMES_TRAIN_SPLIT):\n",
    "        features_split = features[i:(i+INPUT_FRAMES),:]\n",
    "        if FEATURES_NORMALIZED:\n",
    "            means = np.mean(features_split, axis=0)\n",
    "            stds = np.std(features_split, axis=0)\n",
    "            features_split = (features_split-means)/stds\n",
    "        x_train_list.append(features_split)\n",
    "        index = np.where(train_labels[:,0]==filename.replace('.npy', '.wav'))[0][0]\n",
    "        y_train_list.append(train_labels[index,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95583, 95583, numpy.ndarray, (297, 80))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_list), len(y_train_list), type(x_train_list[0]), x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 292, 500)          240500    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 143, 500)          1750500   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 143, 500)          250500    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 143, 3000)         1503000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1500)              4501500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 600)               900600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 3606      \n",
      "=================================================================\n",
      "Total params: 9,150,206\n",
      "Trainable params: 9,150,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "INPUT_FRAMES_FEATURES = x_train_list[0].shape[1]\n",
    "N_OUTPUTS = 6\n",
    "model = Sequential()\n",
    "model.add(Conv1D(500, 6, strides=1, activation='relu', input_shape=(INPUT_FRAMES, INPUT_FRAMES_FEATURES)))\n",
    "model.add(Conv1D(500, 7, strides=2, activation='relu'))\n",
    "model.add(Conv1D(500, 1, strides=1, activation='relu'))\n",
    "model.add(Conv1D(3000, 1, strides=1, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1500, activation='relu', kernel_regularizer=l2(REGULARIZATION)))\n",
    "if DROPOUT>0:\n",
    "    model.add(Dropout(rate=DROPOUT))\n",
    "model.add(Dense(600, activation='relu', kernel_regularizer=l2(REGULARIZATION)))\n",
    "model.add(Dense(N_OUTPUTS, activation='softmax', kernel_regularizer=l2(REGULARIZATION)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test features and targets (into arrays for Keras model predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.loadtxt('../Data/test_labels.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = [], []\n",
    "for filename in os.listdir(dir_test):\n",
    "    features = np.load(dir_test+filename)\n",
    "    if FEATURES_NORMALIZED:\n",
    "        means = np.mean(features, axis=0)\n",
    "        stds = np.std(features, axis=0)\n",
    "        features = (features-means)/stds\n",
    "    x_test.append(features)\n",
    "    index = np.where(test_labels[:,0]==filename.replace('.npy', '.wav'))[0][0]\n",
    "    y_test.append(test_labels[index,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3130, 297, 80), (3130,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert test targets to *keras.utils.to_categorical* format using this languages mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {'estonian':0,'farsi':1,'german':2,'kabyle':3,'mandarin':4,'spanish':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dummies = to_categorical([languages[y] for y in y_test], N_OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3130, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the *generator* function to load the list of training samples features by batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "def generator(x_train_list, y_train_list, batch_size):\n",
    "    global seed\n",
    "    np.random.seed(seed)\n",
    "    indexes = np.random.choice(len(x_train_list), len(x_train_list), replace=False)\n",
    "    while True:\n",
    "        for i in range(0, len(x_train_list), batch_size):\n",
    "            batch_indexes = indexes[i:(i+batch_size)]\n",
    "            batch_features = np.array([x_train_list[j] for j in batch_indexes])\n",
    "            batch_labels = to_categorical([languages[y_train_list[j]] for j in batch_indexes], N_OUTPUTS)\n",
    "            yield batch_features, batch_labels\n",
    "    seed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='loss', min_delta=0.01, patience=3),\n",
    "             EarlyStopping(monitor='acc', min_delta=0.01, patience=3),\n",
    "             EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5),\n",
    "             EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5),\n",
    "             ModelCheckpoint('outputs/'+model_id+'.h5', monitor='val_loss', save_best_only=True)\n",
    "            ]\n",
    "opt = Adam(amsgrad=True, lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 40\n",
    "SAMPLES_PER_EPOCH = len(range(0, len(x_train_list), BATCH_SIZE))\n",
    "history = model.fit_generator(generator = generator(x_train_list, y_train_list, BATCH_SIZE),\n",
    "                              samples_per_epoch = SAMPLES_PER_EPOCH,                             \n",
    "                              nb_epoch = EPOCHS,\n",
    "                              callbacks = callbacks,\n",
    "                              validation_data = (x_test, y_test_dummies),\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(history.history, open('outputs/'+model_id+'.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
